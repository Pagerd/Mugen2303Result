+ source ../common/common_lib.sh
++ source /root/mugen/libs/locallibs/common_lib.sh
+++ python3 --version
+++ '[' 0 -eq 0 ']'
+++ source /root/mugen/libs/locallibs/common_lib_python.sh
+ main
++ type -t post_test
+ '[' -n function ']'
+ trap post_test EXIT INT HUP TERM
+ rpm -qa
+ grep expect
++ type -t config_params
+ '[' -n '' ']'
++ type -t pre_test
+ '[' -n function ']'
+ pre_test
+ LOG_INFO 'Start environmental preparation.'
+ message='Start environmental preparation.'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level info --message 'Start environmental preparation.'
Thu Jul  6 20:28:18 2023 - INFO  - Start environmental preparation.
+++ dirname oe_test_service_hadoop-zkfc.sh
++ cd .
++ cd common
++ pwd
+ common_path=/root/mugen/testcases/cli-test/hadoop/common
++ hostname
+ host_name=openeuler-riscv64
+ name_host=HadoopX
+ hostname
+ grep -i HadoopX
+ hostnamectl set-hostname HadoopX
+ DNF_INSTALL 'hadoop-hdfs hadoop-mapreduce hadoop-yarn java-1.8.0-openjdk apache-zookeeper'
+ pkgs='hadoop-hdfs hadoop-mapreduce hadoop-yarn java-1.8.0-openjdk apache-zookeeper'
+ node=1
+ '[' -z '' ']'
+ tmpfile=
++ python3 /root/mugen/libs/locallibs/rpm_manage.py install --pkgs 'hadoop-hdfs hadoop-mapreduce hadoop-yarn java-1.8.0-openjdk apache-zookeeper' --node 1 --tempfile ''
+ tmpfile2='Last metadata expiration check: 0:07:10 ago on Thu 06 Jul 2023 08:21:59 PM CST.
No match for argument: hadoop-hdfs
No match for argument: hadoop-mapreduce
No match for argument: hadoop-yarn
Package java-1.8.0-openjdk-1:1.8.0.352.b08-5.oe2303.riscv64 is already installed.
No match for argument: apache-zookeeper
Error: Unable to find a match: hadoop-hdfs hadoop-mapreduce hadoop-yarn apache-zookeeper'
+ '[' -z '' ']'
+ tmpfile='Last metadata expiration check: 0:07:10 ago on Thu 06 Jul 2023 08:21:59 PM CST.
No match for argument: hadoop-hdfs
No match for argument: hadoop-mapreduce
No match for argument: hadoop-yarn
Package java-1.8.0-openjdk-1:1.8.0.352.b08-5.oe2303.riscv64 is already installed.
No match for argument: apache-zookeeper
Error: Unable to find a match: hadoop-hdfs hadoop-mapreduce hadoop-yarn apache-zookeeper'
+ echo 'export JAVA_HOME=/usr/lib/jvm/jre'
+ sed -i '/Group=hadoop/a SuccessExitStatus=143' /usr/lib/systemd/system/hadoop-zkfc.service
sed: can't read /usr/lib/systemd/system/hadoop-zkfc.service: No such file or directory
+ systemctl daemon-reload
+ echo '10.0.0.1 HadoopX
    10.0.0.4 HadoopX1
    10.0.0.7 HadoopX2'
+ rm -rf '/tmp/hsperfdata*' '/tmp/hadoop*' /opt/hadoop /var/lib/hadoop-hdfs
+ SSH_CMD '
    hostname | grep -i HadoopX || hostnamectl set-hostname HadoopX1
    dnf -y install hadoop-hdfs hadoop-mapreduce hadoop-yarn java-1.8.0-openjdk apache-zookeeper
    echo '\''export JAVA_HOME=/usr/lib/jvm/jre'\'' >>/usr/libexec/hadoop-layout.sh
    sed -i '\''/Group=hadoop/a SuccessExitStatus=143'\'' /usr/lib/systemd/system/hadoop-zkfc.service
    systemctl daemon-reload
    echo '\''10.0.0.1 HadoopX
    10.0.0.4 HadoopX1
    10.0.0.7 HadoopX2'\'' >>/etc/hosts
    rm -rf /tmp/hsperfdata* /tmp/hadoop* /opt/hadoop /var/lib/hadoop-hdfs
    ' 10.0.0.4 'openEuler12#$' root
+ cmd='
    hostname | grep -i HadoopX || hostnamectl set-hostname HadoopX1
    dnf -y install hadoop-hdfs hadoop-mapreduce hadoop-yarn java-1.8.0-openjdk apache-zookeeper
    echo '\''export JAVA_HOME=/usr/lib/jvm/jre'\'' >>/usr/libexec/hadoop-layout.sh
    sed -i '\''/Group=hadoop/a SuccessExitStatus=143'\'' /usr/lib/systemd/system/hadoop-zkfc.service
    systemctl daemon-reload
    echo '\''10.0.0.1 HadoopX
    10.0.0.4 HadoopX1
    10.0.0.7 HadoopX2'\'' >>/etc/hosts
    rm -rf /tmp/hsperfdata* /tmp/hadoop* /opt/hadoop /var/lib/hadoop-hdfs
    '
+ remoteip=10.0.0.4
+ remotepasswd='openEuler12#$'
+ remoteuser=root
+ timeout=300
+ connport=22
+ bash /root/mugen/libs/locallibs/sshcmd.sh -c '
    hostname | grep -i HadoopX || hostnamectl set-hostname HadoopX1
    dnf -y install hadoop-hdfs hadoop-mapreduce hadoop-yarn java-1.8.0-openjdk apache-zookeeper
    echo '\''export JAVA_HOME=/usr/lib/jvm/jre'\'' >>/usr/libexec/hadoop-layout.sh
    sed -i '\''/Group=hadoop/a SuccessExitStatus=143'\'' /usr/lib/systemd/system/hadoop-zkfc.service
    systemctl daemon-reload
    echo '\''10.0.0.1 HadoopX
    10.0.0.4 HadoopX1
    10.0.0.7 HadoopX2'\'' >>/etc/hosts
    rm -rf /tmp/hsperfdata* /tmp/hadoop* /opt/hadoop /var/lib/hadoop-hdfs
    ' -i 10.0.0.4 -u root -p 'openEuler12#$' -t 300 -o 22
Thu Jul  6 20:29:20 2023 - WARN  - the remote user uses the default configuration.
Thu Jul  6 20:29:21 2023 - WARN  - the remote password uses the default configuration.
Thu Jul  6 20:29:22 2023 - WARN  - the connect port using the default configuration
spawn ssh -o ConnectTimeout=300 -p 22 root@10.0.0.4 
    hostname | grep -i HadoopX || hostnamectl set-hostname HadoopX1
    dnf -y install hadoop-hdfs hadoop-mapreduce hadoop-yarn java-1.8.0-openjdk apache-zookeeper
    echo 'export JAVA_HOME=/usr/lib/jvm/jre' >>/usr/libexec/hadoop-layout.sh
    sed -i '/Group=hadoop/a SuccessExitStatus=143' /usr/lib/systemd/system/hadoop-zkfc.service
    systemctl daemon-reload
    echo '10.0.0.1 HadoopX
    10.0.0.4 HadoopX1
    10.0.0.7 HadoopX2' >>/etc/hosts
    rm -rf /tmp/hsperfdata* /tmp/hadoop* /opt/hadoop /var/lib/hadoop-hdfs
    
root@10.0.0.4's password: 
Last metadata expiration check: 6:55:44 ago on Thu 06 Jul 2023 01:33:52 PM CST.
No match for argument: hadoop-hdfs
No match for argument: hadoop-mapreduce
No match for argument: hadoop-yarn
No match for argument: apache-zookeeper
Error: Unable to find a match: hadoop-hdfs hadoop-mapreduce hadoop-yarn apache-zookeeper
sed: can't read /usr/lib/systemd/system/hadoop-zkfc.service: No such file or directory
+ ret=0
+ test 0 -ne 0
+ return 0
+ SSH_CMD '
    hostname | grep -i HadoopX || hostnamectl set-hostname HadoopX2
    dnf -y install hadoop-hdfs hadoop-mapreduce hadoop-yarn java-1.8.0-openjdk apache-zookeeper
    echo '\''export JAVA_HOME=/usr/lib/jvm/jre'\'' >>/usr/libexec/hadoop-layout.sh
    sed -i '\''/Group=hadoop/a SuccessExitStatus=143'\'' /usr/lib/systemd/system/hadoop-zkfc.service
    systemctl daemon-reload
    echo '\''10.0.0.1 HadoopX
    10.0.0.4 HadoopX1
    10.0.0.7 HadoopX2'\'' >>/etc/hosts
    rm -rf /tmp/hsperfdata* /tmp/hadoop* /opt/hadoop /var/lib/hadoop-hdfs
    ' 10.0.0.7 'openEuler12#$' root
+ cmd='
    hostname | grep -i HadoopX || hostnamectl set-hostname HadoopX2
    dnf -y install hadoop-hdfs hadoop-mapreduce hadoop-yarn java-1.8.0-openjdk apache-zookeeper
    echo '\''export JAVA_HOME=/usr/lib/jvm/jre'\'' >>/usr/libexec/hadoop-layout.sh
    sed -i '\''/Group=hadoop/a SuccessExitStatus=143'\'' /usr/lib/systemd/system/hadoop-zkfc.service
    systemctl daemon-reload
    echo '\''10.0.0.1 HadoopX
    10.0.0.4 HadoopX1
    10.0.0.7 HadoopX2'\'' >>/etc/hosts
    rm -rf /tmp/hsperfdata* /tmp/hadoop* /opt/hadoop /var/lib/hadoop-hdfs
    '
+ remoteip=10.0.0.7
+ remotepasswd='openEuler12#$'
+ remoteuser=root
+ timeout=300
+ connport=22
+ bash /root/mugen/libs/locallibs/sshcmd.sh -c '
    hostname | grep -i HadoopX || hostnamectl set-hostname HadoopX2
    dnf -y install hadoop-hdfs hadoop-mapreduce hadoop-yarn java-1.8.0-openjdk apache-zookeeper
    echo '\''export JAVA_HOME=/usr/lib/jvm/jre'\'' >>/usr/libexec/hadoop-layout.sh
    sed -i '\''/Group=hadoop/a SuccessExitStatus=143'\'' /usr/lib/systemd/system/hadoop-zkfc.service
    systemctl daemon-reload
    echo '\''10.0.0.1 HadoopX
    10.0.0.4 HadoopX1
    10.0.0.7 HadoopX2'\'' >>/etc/hosts
    rm -rf /tmp/hsperfdata* /tmp/hadoop* /opt/hadoop /var/lib/hadoop-hdfs
    ' -i 10.0.0.7 -u root -p 'openEuler12#$' -t 300 -o 22
Thu Jul  6 20:29:46 2023 - WARN  - the remote user uses the default configuration.
Thu Jul  6 20:29:47 2023 - WARN  - the remote password uses the default configuration.
Thu Jul  6 20:29:48 2023 - WARN  - the connect port using the default configuration
spawn ssh -o ConnectTimeout=300 -p 22 root@10.0.0.7 
    hostname | grep -i HadoopX || hostnamectl set-hostname HadoopX2
    dnf -y install hadoop-hdfs hadoop-mapreduce hadoop-yarn java-1.8.0-openjdk apache-zookeeper
    echo 'export JAVA_HOME=/usr/lib/jvm/jre' >>/usr/libexec/hadoop-layout.sh
    sed -i '/Group=hadoop/a SuccessExitStatus=143' /usr/lib/systemd/system/hadoop-zkfc.service
    systemctl daemon-reload
    echo '10.0.0.1 HadoopX
    10.0.0.4 HadoopX1
    10.0.0.7 HadoopX2' >>/etc/hosts
    rm -rf /tmp/hsperfdata* /tmp/hadoop* /opt/hadoop /var/lib/hadoop-hdfs
    
root@10.0.0.7's password: 
Last metadata expiration check: 6:56:11 ago on Thu 06 Jul 2023 01:33:52 PM CST.
No match for argument: hadoop-hdfs
No match for argument: hadoop-mapreduce
No match for argument: hadoop-yarn
No match for argument: apache-zookeeper
Error: Unable to find a match: hadoop-hdfs hadoop-mapreduce hadoop-yarn apache-zookeeper
sed: can't read /usr/lib/systemd/system/hadoop-zkfc.service: No such file or directory
+ ret=0
+ test 0 -ne 0
+ return 0
+ cp ./common/core-site.xml ./common/hadoop-env.sh ./common/hdfs-site.xml ./common/yarn-site.xml /etc/hadoop/
cp: target '/etc/hadoop/' is not a directory
+ SSH_SCP /root/mugen/testcases/cli-test/hadoop/common/ root@10.0.0.4:/tmp/ 'openEuler12#$'
+ src=/root/mugen/testcases/cli-test/hadoop/common/
+ dest=root@10.0.0.4:/tmp/
+ remotepasswd='openEuler12#$'
+ connport=22
+ bash /root/mugen/libs/locallibs/sshscp.sh -p 'openEuler12#$' -o 22 -s /root/mugen/testcases/cli-test/hadoop/common/ -d root@10.0.0.4:/tmp/
Thu Jul  6 20:30:13 2023 - WARN  - the remote password uses the default configuration.
Thu Jul  6 20:30:14 2023 - WARN  - the connect port using the default configuration
spawn scp -P 22 -r /root/mugen/testcases/cli-test/hadoop/common/ root@10.0.0.4:/tmp/
root@10.0.0.4's password: 
core-site.xml                                   0%    0     0.0KB/s   --:-- ETAcore-site.xml                                 100% 1725    69.0KB/s   00:00    
hdfs-site.xml                                   0%    0     0.0KB/s   --:-- ETAhdfs-site.xml                                 100% 3784   408.7KB/s   00:00    
yarn-site.xml                                   0%    0     0.0KB/s   --:-- ETAyarn-site.xml                                 100% 3879   441.2KB/s   00:00    
hadoop-env.sh                                   0%    0     0.0KB/s   --:-- ETAhadoop-env.sh                                 100%   52     7.3KB/s   00:00    
+ ret=0
+ test 0 -ne 0
+ return 0
+ SSH_SCP /root/mugen/testcases/cli-test/hadoop/common/ root@10.0.0.7:/tmp/ 'openEuler12#$'
+ src=/root/mugen/testcases/cli-test/hadoop/common/
+ dest=root@10.0.0.7:/tmp/
+ remotepasswd='openEuler12#$'
+ connport=22
+ bash /root/mugen/libs/locallibs/sshscp.sh -p 'openEuler12#$' -o 22 -s /root/mugen/testcases/cli-test/hadoop/common/ -d root@10.0.0.7:/tmp/
Thu Jul  6 20:30:21 2023 - WARN  - the remote password uses the default configuration.
Thu Jul  6 20:30:22 2023 - WARN  - the connect port using the default configuration
spawn scp -P 22 -r /root/mugen/testcases/cli-test/hadoop/common/ root@10.0.0.7:/tmp/
root@10.0.0.7's password: 
core-site.xml                                   0%    0     0.0KB/s   --:-- ETAcore-site.xml                                 100% 1725   119.6KB/s   00:00    
hdfs-site.xml                                   0%    0     0.0KB/s   --:-- ETAhdfs-site.xml                                 100% 3784   434.6KB/s   00:00    
yarn-site.xml                                   0%    0     0.0KB/s   --:-- ETAyarn-site.xml                                 100% 3879   631.1KB/s   00:00    
hadoop-env.sh                                   0%    0     0.0KB/s   --:-- ETAhadoop-env.sh                                 100%   52     8.7KB/s   00:00    
+ ret=0
+ test 0 -ne 0
+ return 0
+ systemctl start zookeeper
Failed to start zookeeper.service: Unit zookeeper.service not found.
+ hadoop-daemon.sh start journalnode
oe_test_service_hadoop-zkfc.sh: line 66: hadoop-daemon.sh: command not found
+ which firewalld
which: no firewalld in (/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin)
+ SSH_CMD '
    mv /tmp/common/* /etc/hadoop
    systemctl start zookeeper
    hadoop-daemon.sh start journalnode
    which firewalld && systemctl stop firewalld
    ' 10.0.0.4 'openEuler12#$' root
+ cmd='
    mv /tmp/common/* /etc/hadoop
    systemctl start zookeeper
    hadoop-daemon.sh start journalnode
    which firewalld && systemctl stop firewalld
    '
+ remoteip=10.0.0.4
+ remotepasswd='openEuler12#$'
+ remoteuser=root
+ timeout=300
+ connport=22
+ bash /root/mugen/libs/locallibs/sshcmd.sh -c '
    mv /tmp/common/* /etc/hadoop
    systemctl start zookeeper
    hadoop-daemon.sh start journalnode
    which firewalld && systemctl stop firewalld
    ' -i 10.0.0.4 -u root -p 'openEuler12#$' -t 300 -o 22
Thu Jul  6 20:30:29 2023 - WARN  - the remote user uses the default configuration.
Thu Jul  6 20:30:30 2023 - WARN  - the remote password uses the default configuration.
Thu Jul  6 20:30:31 2023 - WARN  - the connect port using the default configuration
spawn ssh -o ConnectTimeout=300 -p 22 root@10.0.0.4 
    mv /tmp/common/* /etc/hadoop
    systemctl start zookeeper
    hadoop-daemon.sh start journalnode
    which firewalld && systemctl stop firewalld
    
root@10.0.0.4's password: 
mv: target '/etc/hadoop' is not a directory
Failed to start zookeeper.service: Unit zookeeper.service not found.
bash: line 4: hadoop-daemon.sh: command not found
which: no firewalld in (/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin)
+ ret=1
+ test 1 -ne 0
+ LOG_ERROR 'Failed in remote CMD operation:1'
+ message='Failed in remote CMD operation:1'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level error --message 'Failed in remote CMD operation:1'
Thu Jul  6 20:30:38 2023 - ERROR - Failed in remote CMD operation:1
+ return 1
+ SSH_CMD '
    mv /tmp/common/* /etc/hadoop
    systemctl start zookeeper
    hadoop-daemon.sh start journalnode
    which firewalld && systemctl stop firewalld
    ' 10.0.0.7 'openEuler12#$' root
+ cmd='
    mv /tmp/common/* /etc/hadoop
    systemctl start zookeeper
    hadoop-daemon.sh start journalnode
    which firewalld && systemctl stop firewalld
    '
+ remoteip=10.0.0.7
+ remotepasswd='openEuler12#$'
+ remoteuser=root
+ timeout=300
+ connport=22
+ bash /root/mugen/libs/locallibs/sshcmd.sh -c '
    mv /tmp/common/* /etc/hadoop
    systemctl start zookeeper
    hadoop-daemon.sh start journalnode
    which firewalld && systemctl stop firewalld
    ' -i 10.0.0.7 -u root -p 'openEuler12#$' -t 300 -o 22
Thu Jul  6 20:30:39 2023 - WARN  - the remote user uses the default configuration.
Thu Jul  6 20:30:40 2023 - WARN  - the remote password uses the default configuration.
Thu Jul  6 20:30:41 2023 - WARN  - the connect port using the default configuration
spawn ssh -o ConnectTimeout=300 -p 22 root@10.0.0.7 
    mv /tmp/common/* /etc/hadoop
    systemctl start zookeeper
    hadoop-daemon.sh start journalnode
    which firewalld && systemctl stop firewalld
    
root@10.0.0.7's password: 
mv: target '/etc/hadoop' is not a directory
Failed to start zookeeper.service: Unit zookeeper.service not found.
bash: line 4: hadoop-daemon.sh: command not found
which: no firewalld in (/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin)
+ ret=1
+ test 1 -ne 0
+ LOG_ERROR 'Failed in remote CMD operation:1'
+ message='Failed in remote CMD operation:1'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level error --message 'Failed in remote CMD operation:1'
Thu Jul  6 20:30:47 2023 - ERROR - Failed in remote CMD operation:1
+ return 1
+ expect
spawn sudo -u hdfs hdfs namenode -format
sudo: unknown user hdfs
sudo: error initializing audit plugin sudoers_audit
expect: spawn id exp3 not open
    while executing
"expect eof"
+ LOG_INFO 'End of environmental preparation!'
+ message='End of environmental preparation!'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level info --message 'End of environmental preparation!'
Thu Jul  6 20:30:49 2023 - INFO  - End of environmental preparation!
++ type -t run_test
+ '[' -n function ']'
+ run_test
+ LOG_INFO 'Start testing...'
+ message='Start testing...'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level info --message 'Start testing...'
Thu Jul  6 20:30:50 2023 - INFO  - Start testing...
+ expect
spawn hdfs zkfc -formatZK
couldn't execute "hdfs": no such file or directory
    while executing
"spawn hdfs zkfc -formatZK"
+ SLEEP_WAIT 20
+ wait_time=20
+ cmd=
+ mode=1
+ python3 /root/mugen/libs/locallibs/sleep_wait.py --time 20 --cmd '' --mode 1
+ test_execution hadoop-zkfc.service
+ service=hadoop-zkfc.service
++ date '+%Y-%m-%d %T'
+ log_time='2023-07-06 20:31:12'
+ test_restart hadoop-zkfc.service
+ service=hadoop-zkfc.service
+ systemctl restart hadoop-zkfc.service
Failed to restart hadoop-zkfc.service: Unit hadoop-zkfc.service not found.
+ CHECK_RESULT 5 0 0 'hadoop-zkfc.service restart failed'
+ actual_result=5
+ expect_result=0
+ mode=0
+ error_log='hadoop-zkfc.service restart failed'
+ exit_mode=0
+ '[' -z 5 ']'
+ '[' 0 -eq 0 ']'
+ test 5x '!=' 0x
+ test -n 'hadoop-zkfc.service restart failed'
+ LOG_ERROR 'hadoop-zkfc.service restart failed'
+ message='hadoop-zkfc.service restart failed'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level error --message 'hadoop-zkfc.service restart failed'
Thu Jul  6 20:31:13 2023 - ERROR - hadoop-zkfc.service restart failed
+ (( exec_result++ ))
+ LOG_ERROR '../common/common_lib.sh line 34'
+ message='../common/common_lib.sh line 34'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level error --message '../common/common_lib.sh line 34'
Thu Jul  6 20:31:14 2023 - ERROR - ../common/common_lib.sh line 34
+ '[' 0 -eq 1 ']'
+ return 0
+ SLEEP_WAIT 5
+ wait_time=5
+ cmd=
+ mode=1
+ python3 /root/mugen/libs/locallibs/sleep_wait.py --time 5 --cmd '' --mode 1
+ systemctl status hadoop-zkfc.service
+ grep 'Active: active'
Unit hadoop-zkfc.service could not be found.
+ CHECK_RESULT 1 0 0 'hadoop-zkfc.service restart failed'
+ actual_result=1
+ expect_result=0
+ mode=0
+ error_log='hadoop-zkfc.service restart failed'
+ exit_mode=0
+ '[' -z 1 ']'
+ '[' 0 -eq 0 ']'
+ test 1x '!=' 0x
+ test -n 'hadoop-zkfc.service restart failed'
+ LOG_ERROR 'hadoop-zkfc.service restart failed'
+ message='hadoop-zkfc.service restart failed'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level error --message 'hadoop-zkfc.service restart failed'
Thu Jul  6 20:31:22 2023 - ERROR - hadoop-zkfc.service restart failed
+ (( exec_result++ ))
+ LOG_ERROR '../common/common_lib.sh line 37'
+ message='../common/common_lib.sh line 37'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level error --message '../common/common_lib.sh line 37'
Thu Jul  6 20:31:23 2023 - ERROR - ../common/common_lib.sh line 37
+ '[' 0 -eq 1 ']'
+ return 0
+ systemctl stop hadoop-zkfc.service
Failed to stop hadoop-zkfc.service: Unit hadoop-zkfc.service not loaded.
+ CHECK_RESULT 5 0 0 'hadoop-zkfc.service stop failed'
+ actual_result=5
+ expect_result=0
+ mode=0
+ error_log='hadoop-zkfc.service stop failed'
+ exit_mode=0
+ '[' -z 5 ']'
+ '[' 0 -eq 0 ']'
+ test 5x '!=' 0x
+ test -n 'hadoop-zkfc.service stop failed'
+ LOG_ERROR 'hadoop-zkfc.service stop failed'
+ message='hadoop-zkfc.service stop failed'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level error --message 'hadoop-zkfc.service stop failed'
Thu Jul  6 20:31:24 2023 - ERROR - hadoop-zkfc.service stop failed
+ (( exec_result++ ))
+ LOG_ERROR '../common/common_lib.sh line 39'
+ message='../common/common_lib.sh line 39'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level error --message '../common/common_lib.sh line 39'
Thu Jul  6 20:31:25 2023 - ERROR - ../common/common_lib.sh line 39
+ '[' 0 -eq 1 ']'
+ return 0
+ SLEEP_WAIT 5
+ wait_time=5
+ cmd=
+ mode=1
+ python3 /root/mugen/libs/locallibs/sleep_wait.py --time 5 --cmd '' --mode 1
+ systemctl status hadoop-zkfc.service
+ grep 'Active: inactive'
Unit hadoop-zkfc.service could not be found.
+ CHECK_RESULT 1 0 0 'hadoop-zkfc.service stop failed'
+ actual_result=1
+ expect_result=0
+ mode=0
+ error_log='hadoop-zkfc.service stop failed'
+ exit_mode=0
+ '[' -z 1 ']'
+ '[' 0 -eq 0 ']'
+ test 1x '!=' 0x
+ test -n 'hadoop-zkfc.service stop failed'
+ LOG_ERROR 'hadoop-zkfc.service stop failed'
+ message='hadoop-zkfc.service stop failed'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level error --message 'hadoop-zkfc.service stop failed'
Thu Jul  6 20:31:32 2023 - ERROR - hadoop-zkfc.service stop failed
+ (( exec_result++ ))
+ LOG_ERROR '../common/common_lib.sh line 42'
+ message='../common/common_lib.sh line 42'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level error --message '../common/common_lib.sh line 42'
Thu Jul  6 20:31:33 2023 - ERROR - ../common/common_lib.sh line 42
+ '[' 0 -eq 1 ']'
+ return 0
+ systemctl start hadoop-zkfc.service
Failed to start hadoop-zkfc.service: Unit hadoop-zkfc.service not found.
+ CHECK_RESULT 5 0 0 'hadoop-zkfc.service start failed'
+ actual_result=5
+ expect_result=0
+ mode=0
+ error_log='hadoop-zkfc.service start failed'
+ exit_mode=0
+ '[' -z 5 ']'
+ '[' 0 -eq 0 ']'
+ test 5x '!=' 0x
+ test -n 'hadoop-zkfc.service start failed'
+ LOG_ERROR 'hadoop-zkfc.service start failed'
+ message='hadoop-zkfc.service start failed'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level error --message 'hadoop-zkfc.service start failed'
Thu Jul  6 20:31:35 2023 - ERROR - hadoop-zkfc.service start failed
+ (( exec_result++ ))
+ LOG_ERROR '../common/common_lib.sh line 44'
+ message='../common/common_lib.sh line 44'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level error --message '../common/common_lib.sh line 44'
Thu Jul  6 20:31:35 2023 - ERROR - ../common/common_lib.sh line 44
+ '[' 0 -eq 1 ']'
+ return 0
+ SLEEP_WAIT 5
+ wait_time=5
+ cmd=
+ mode=1
+ python3 /root/mugen/libs/locallibs/sleep_wait.py --time 5 --cmd '' --mode 1
+ systemctl status hadoop-zkfc.service
+ grep 'Active: active'
Unit hadoop-zkfc.service could not be found.
+ CHECK_RESULT 1 0 0 'hadoop-zkfc.service start failed'
+ actual_result=1
+ expect_result=0
+ mode=0
+ error_log='hadoop-zkfc.service start failed'
+ exit_mode=0
+ '[' -z 1 ']'
+ '[' 0 -eq 0 ']'
+ test 1x '!=' 0x
+ test -n 'hadoop-zkfc.service start failed'
+ LOG_ERROR 'hadoop-zkfc.service start failed'
+ message='hadoop-zkfc.service start failed'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level error --message 'hadoop-zkfc.service start failed'
Thu Jul  6 20:31:43 2023 - ERROR - hadoop-zkfc.service start failed
+ (( exec_result++ ))
+ LOG_ERROR '../common/common_lib.sh line 47'
+ message='../common/common_lib.sh line 47'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level error --message '../common/common_lib.sh line 47'
Thu Jul  6 20:31:44 2023 - ERROR - ../common/common_lib.sh line 47
+ '[' 0 -eq 1 ']'
+ return 0
+ test_enabled hadoop-zkfc.service
+ service=hadoop-zkfc.service
++ systemctl is-enabled hadoop-zkfc.service
Failed to get unit file state for hadoop-zkfc.service: No such file or directory
+ state=
+ '[' '' == enabled ']'
+ '[' '' == disabled ']'
+ '[' '' == masked ']'
+ '[' '' == static ']'
+ LOG_INFO 'Unit is indirect, ignoring.'
+ message='Unit is indirect, ignoring.'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level info --message 'Unit is indirect, ignoring.'
Thu Jul  6 20:31:45 2023 - INFO  - Unit is indirect, ignoring.
+ journalctl --since '2023-07-06 20:31:12' -u hadoop-zkfc.service
+ grep -i 'fail\|error'
+ grep -v -i 'DEBUG\|INFO\|WARNING'
+ CHECK_RESULT 1 0 1 'There is an error message for the log of hadoop-zkfc.service'
+ actual_result=1
+ expect_result=0
+ mode=1
+ error_log='There is an error message for the log of hadoop-zkfc.service'
+ exit_mode=0
+ '[' -z 1 ']'
+ '[' 1 -eq 0 ']'
+ test 1x == 0x
+ return 0
+ test_reload hadoop-zkfc.service
+ service=hadoop-zkfc.service
+ systemctl start hadoop-zkfc.service
Failed to start hadoop-zkfc.service: Unit hadoop-zkfc.service not found.
+ systemctl reload hadoop-zkfc.service
+ grep 'Job type reload is not applicable'
+ CHECK_RESULT 1 0 0 'Job type reload is not applicable for unit hadoop-zkfc.service'
+ actual_result=1
+ expect_result=0
+ mode=0
+ error_log='Job type reload is not applicable for unit hadoop-zkfc.service'
+ exit_mode=0
+ '[' -z 1 ']'
+ '[' 0 -eq 0 ']'
+ test 1x '!=' 0x
+ test -n 'Job type reload is not applicable for unit hadoop-zkfc.service'
+ LOG_ERROR 'Job type reload is not applicable for unit hadoop-zkfc.service'
+ message='Job type reload is not applicable for unit hadoop-zkfc.service'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level error --message 'Job type reload is not applicable for unit hadoop-zkfc.service'
Thu Jul  6 20:31:46 2023 - ERROR - Job type reload is not applicable for unit hadoop-zkfc.service
+ (( exec_result++ ))
+ LOG_ERROR '../common/common_lib.sh line 91'
+ message='../common/common_lib.sh line 91'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level error --message '../common/common_lib.sh line 91'
Thu Jul  6 20:31:47 2023 - ERROR - ../common/common_lib.sh line 91
+ '[' 0 -eq 1 ']'
+ return 0
+ systemctl status hadoop-zkfc.service
+ grep 'Active: active'
Unit hadoop-zkfc.service could not be found.
+ systemctl status hadoop-zkfc.service
+ grep 'inactive (dead)'
Unit hadoop-zkfc.service could not be found.
+ return 1
+ LOG_INFO 'Finish test!'
+ message='Finish test!'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level info --message 'Finish test!'
Thu Jul  6 20:31:49 2023 - INFO  - Finish test!
+ CASE_RESULT 0
+ case_re=0
+ test -z 7
+ test 7 -gt 0
+ LOG_ERROR 'failed to execute the case.'
+ message='failed to execute the case.'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level error --message 'failed to execute the case.'
Thu Jul  6 20:31:49 2023 - ERROR - failed to execute the case.
+ exit 7
+ post_test
+ LOG_INFO 'start environment cleanup.'
+ message='start environment cleanup.'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level info --message 'start environment cleanup.'
Thu Jul  6 20:31:50 2023 - INFO  - start environment cleanup.
+ systemctl stop hadoop-zkfc.service
Failed to stop hadoop-zkfc.service: Unit hadoop-zkfc.service not loaded.
+ systemctl stop zookeeper
Failed to stop zookeeper.service: Unit zookeeper.service not loaded.
+ hadoop-daemon.sh stop journalnode
oe_test_service_hadoop-zkfc.sh: line 118: hadoop-daemon.sh: command not found
++ pgrep -u journalnode
pgrep: invalid user name: journalnode
+ kill -9
kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]
+ sed -i '/export JAVA_HOME=\/usr\/lib\/jvm\/jre/d' /usr/libexec/hadoop-layout.sh
+ sed -i /SuccessExitStatus=143/d /usr/lib/systemd/system/hadoop-zkfc.service
sed: can't read /usr/lib/systemd/system/hadoop-zkfc.service: No such file or directory
+ systemctl daemon-reload
+ DNF_REMOVE
+ node=1
+ pkg_list=
+ mode=0
+ [[ -z Last metadata expiration check: 0:07:10 ago on Thu 06 Jul 2023 08:21:59 PM CST.
No match for argument: hadoop-hdfs
No match for argument: hadoop-mapreduce
No match for argument: hadoop-yarn
Package java-1.8.0-openjdk-1:1.8.0.352.b08-5.oe2303.riscv64 is already installed.
No match for argument: apache-zookeeper
Error: Unable to find a match: hadoop-hdfs hadoop-mapreduce hadoop-yarn apache-zookeeper ]]
+ '[' 0 -ne 0 ']'
+ '[' 1 == 0 ']'
+ python3 /root/mugen/libs/locallibs/rpm_manage.py remove --node 1 --pkgs '' --tempfile 'Last metadata expiration check: 0:07:10 ago on Thu 06 Jul 2023 08:21:59 PM CST.
No match for argument: hadoop-hdfs
No match for argument: hadoop-mapreduce
No match for argument: hadoop-yarn
Package java-1.8.0-openjdk-1:1.8.0.352.b08-5.oe2303.riscv64 is already installed.
No match for argument: apache-zookeeper
Error: Unable to find a match: hadoop-hdfs hadoop-mapreduce hadoop-yarn apache-zookeeper'
Traceback (most recent call last):
  File "/root/mugen/libs/locallibs/rpm_manage.py", line 192, in <module>
    exitcode = rpm_remove(args.node, args.pkgs, args.tempfile)
  File "/root/mugen/libs/locallibs/rpm_manage.py", line 163, in rpm_remove
    with open(tmpfile, "r") as f:
OSError: [Errno 36] File name too long: 'Last metadata expiration check: 0:07:10 ago on Thu 06 Jul 2023 08:21:59 PM CST.\nNo match for argument: hadoop-hdfs\nNo match for argument: hadoop-mapreduce\nNo match for argument: hadoop-yarn\nPackage java-1.8.0-openjdk-1:1.8.0.352.b08-5.oe2303.riscv64 is already installed.\nNo match for argument: apache-zookeeper\nError: Unable to find a match: hadoop-hdfs hadoop-mapreduce hadoop-yarn apache-zookeeper'
+ '[' 0 -ne 0 ']'
+ sed -i /HadoopX/d /etc/hosts
+ hostname
+ grep -i openeuler-riscv64
+ hostnamectl set-hostname openeuler-riscv64
+ which firewalld
which: no firewalld in (/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin)
+ rm -rf '/tmp/hsperfdata*' '/tmp/hadoop*' /opt/hadoop /var/lib/hadoop-hdfs
++ pgrep -u journalnode
pgrep: invalid user name: journalnode
+ SSH_CMD '
    systemctl stop zookeeper
    hadoop-daemon.sh stop journalnode
    kill -9 
    sed -i '\''/export JAVA_HOME=\/usr\/lib\/jvm\/jre/d'\'' /usr/libexec/hadoop-layout.sh
    sed -i '\''/SuccessExitStatus=143/d'\'' /usr/lib/systemd/system/hadoop-zkfc.service
    systemctl daemon-reload
    dnf -y remove hadoop-hdfs hadoop-mapreduce hadoop-yarn  java-1.8.0-openjdk apache-zookeeper
    sed -i '\''/HadoopX/d'\'' /etc/hosts
    hostname | grep -i openeuler-riscv64 || hostnamectl set-hostname openeuler-riscv64
    which firewalld && systemctl start firewalld
    rm -rf /tmp/hsperfdata* /tmp/hadoop* /opt/hadoop /var/lib/hadoop-hdfs /tmp/common
    ' 10.0.0.4 'openEuler12#$' root
+ cmd='
    systemctl stop zookeeper
    hadoop-daemon.sh stop journalnode
    kill -9 
    sed -i '\''/export JAVA_HOME=\/usr\/lib\/jvm\/jre/d'\'' /usr/libexec/hadoop-layout.sh
    sed -i '\''/SuccessExitStatus=143/d'\'' /usr/lib/systemd/system/hadoop-zkfc.service
    systemctl daemon-reload
    dnf -y remove hadoop-hdfs hadoop-mapreduce hadoop-yarn  java-1.8.0-openjdk apache-zookeeper
    sed -i '\''/HadoopX/d'\'' /etc/hosts
    hostname | grep -i openeuler-riscv64 || hostnamectl set-hostname openeuler-riscv64
    which firewalld && systemctl start firewalld
    rm -rf /tmp/hsperfdata* /tmp/hadoop* /opt/hadoop /var/lib/hadoop-hdfs /tmp/common
    '
+ remoteip=10.0.0.4
+ remotepasswd='openEuler12#$'
+ remoteuser=root
+ timeout=300
+ connport=22
+ bash /root/mugen/libs/locallibs/sshcmd.sh -c '
    systemctl stop zookeeper
    hadoop-daemon.sh stop journalnode
    kill -9 
    sed -i '\''/export JAVA_HOME=\/usr\/lib\/jvm\/jre/d'\'' /usr/libexec/hadoop-layout.sh
    sed -i '\''/SuccessExitStatus=143/d'\'' /usr/lib/systemd/system/hadoop-zkfc.service
    systemctl daemon-reload
    dnf -y remove hadoop-hdfs hadoop-mapreduce hadoop-yarn  java-1.8.0-openjdk apache-zookeeper
    sed -i '\''/HadoopX/d'\'' /etc/hosts
    hostname | grep -i openeuler-riscv64 || hostnamectl set-hostname openeuler-riscv64
    which firewalld && systemctl start firewalld
    rm -rf /tmp/hsperfdata* /tmp/hadoop* /opt/hadoop /var/lib/hadoop-hdfs /tmp/common
    ' -i 10.0.0.4 -u root -p 'openEuler12#$' -t 300 -o 22
Thu Jul  6 20:32:05 2023 - WARN  - the remote user uses the default configuration.
Thu Jul  6 20:32:06 2023 - WARN  - the remote password uses the default configuration.
Thu Jul  6 20:32:07 2023 - WARN  - the connect port using the default configuration
spawn ssh -o ConnectTimeout=300 -p 22 root@10.0.0.4 
    systemctl stop zookeeper
    hadoop-daemon.sh stop journalnode
    kill -9 
    sed -i '/export JAVA_HOME=/usr/lib/jvm/jre/d' /usr/libexec/hadoop-layout.sh
    sed -i '/SuccessExitStatus=143/d' /usr/lib/systemd/system/hadoop-zkfc.service
    systemctl daemon-reload
    dnf -y remove hadoop-hdfs hadoop-mapreduce hadoop-yarn  java-1.8.0-openjdk apache-zookeeper
    sed -i '/HadoopX/d' /etc/hosts
    hostname | grep -i openeuler-riscv64 || hostnamectl set-hostname openeuler-riscv64
    which firewalld && systemctl start firewalld
    rm -rf /tmp/hsperfdata* /tmp/hadoop* /opt/hadoop /var/lib/hadoop-hdfs /tmp/common
    
root@10.0.0.4's password: 
Failed to stop zookeeper.service: Unit zookeeper.service not loaded.
bash: line 3: hadoop-daemon.sh: command not found
kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]
sed: -e expression #1, char 20: unknown command: `u'
sed: can't read /usr/lib/systemd/system/hadoop-zkfc.service: No such file or directory
No match for argument: hadoop-hdfs
No match for argument: hadoop-mapreduce
No match for argument: hadoop-yarn
No match for argument: java-1.8.0-openjdk
No match for argument: apache-zookeeper
No packages marked for removal.
Dependencies resolved.
Nothing to do.
Complete!
which: no firewalld in (/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin)
+ ret=0
+ test 0 -ne 0
+ return 0
++ pgrep -u journalnode
pgrep: invalid user name: journalnode
+ SSH_CMD '
    systemctl stop zookeeper
    hadoop-daemon.sh stop journalnode
    kill -9 
    sed -i '\''/export JAVA_HOME=\/usr\/lib\/jvm\/jre/d'\'' /usr/libexec/hadoop-layout.sh
    sed -i '\''/SuccessExitStatus=143/d'\'' /usr/lib/systemd/system/hadoop-zkfc.service
    systemctl daemon-reload
    dnf -y remove hadoop-hdfs hadoop-mapreduce hadoop-yarn  java-1.8.0-openjdk apache-zookeeper
    sed -i '\''/HadoopX/d'\'' /etc/hosts
    hostname | grep -i openeuler-riscv64 || hostnamectl set-hostname openeuler-riscv64
    which firewalld && systemctl start firewalld
    rm -rf /tmp/hsperfdata* /tmp/hadoop* /opt/hadoop /var/lib/hadoop-hdfs /tmp/common
    ' 10.0.0.7 'openEuler12#$' root
+ cmd='
    systemctl stop zookeeper
    hadoop-daemon.sh stop journalnode
    kill -9 
    sed -i '\''/export JAVA_HOME=\/usr\/lib\/jvm\/jre/d'\'' /usr/libexec/hadoop-layout.sh
    sed -i '\''/SuccessExitStatus=143/d'\'' /usr/lib/systemd/system/hadoop-zkfc.service
    systemctl daemon-reload
    dnf -y remove hadoop-hdfs hadoop-mapreduce hadoop-yarn  java-1.8.0-openjdk apache-zookeeper
    sed -i '\''/HadoopX/d'\'' /etc/hosts
    hostname | grep -i openeuler-riscv64 || hostnamectl set-hostname openeuler-riscv64
    which firewalld && systemctl start firewalld
    rm -rf /tmp/hsperfdata* /tmp/hadoop* /opt/hadoop /var/lib/hadoop-hdfs /tmp/common
    '
+ remoteip=10.0.0.7
+ remotepasswd='openEuler12#$'
+ remoteuser=root
+ timeout=300
+ connport=22
+ bash /root/mugen/libs/locallibs/sshcmd.sh -c '
    systemctl stop zookeeper
    hadoop-daemon.sh stop journalnode
    kill -9 
    sed -i '\''/export JAVA_HOME=\/usr\/lib\/jvm\/jre/d'\'' /usr/libexec/hadoop-layout.sh
    sed -i '\''/SuccessExitStatus=143/d'\'' /usr/lib/systemd/system/hadoop-zkfc.service
    systemctl daemon-reload
    dnf -y remove hadoop-hdfs hadoop-mapreduce hadoop-yarn  java-1.8.0-openjdk apache-zookeeper
    sed -i '\''/HadoopX/d'\'' /etc/hosts
    hostname | grep -i openeuler-riscv64 || hostnamectl set-hostname openeuler-riscv64
    which firewalld && systemctl start firewalld
    rm -rf /tmp/hsperfdata* /tmp/hadoop* /opt/hadoop /var/lib/hadoop-hdfs /tmp/common
    ' -i 10.0.0.7 -u root -p 'openEuler12#$' -t 300 -o 22
Thu Jul  6 20:32:30 2023 - WARN  - the remote user uses the default configuration.
Thu Jul  6 20:32:31 2023 - WARN  - the remote password uses the default configuration.
Thu Jul  6 20:32:32 2023 - WARN  - the connect port using the default configuration
spawn ssh -o ConnectTimeout=300 -p 22 root@10.0.0.7 
    systemctl stop zookeeper
    hadoop-daemon.sh stop journalnode
    kill -9 
    sed -i '/export JAVA_HOME=/usr/lib/jvm/jre/d' /usr/libexec/hadoop-layout.sh
    sed -i '/SuccessExitStatus=143/d' /usr/lib/systemd/system/hadoop-zkfc.service
    systemctl daemon-reload
    dnf -y remove hadoop-hdfs hadoop-mapreduce hadoop-yarn  java-1.8.0-openjdk apache-zookeeper
    sed -i '/HadoopX/d' /etc/hosts
    hostname | grep -i openeuler-riscv64 || hostnamectl set-hostname openeuler-riscv64
    which firewalld && systemctl start firewalld
    rm -rf /tmp/hsperfdata* /tmp/hadoop* /opt/hadoop /var/lib/hadoop-hdfs /tmp/common
    
root@10.0.0.7's password: 
Failed to stop zookeeper.service: Unit zookeeper.service not loaded.
bash: line 3: hadoop-daemon.sh: command not found
kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]
sed: -e expression #1, char 20: unknown command: `u'
sed: can't read /usr/lib/systemd/system/hadoop-zkfc.service: No such file or directory
No match for argument: hadoop-hdfs
No match for argument: hadoop-mapreduce
No match for argument: hadoop-yarn
No match for argument: java-1.8.0-openjdk
No match for argument: apache-zookeeper
No packages marked for removal.
Dependencies resolved.
Nothing to do.
Complete!
which: no firewalld in (/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin)
+ ret=0
+ test 0 -ne 0
+ return 0
+ LOG_INFO 'Finish environment cleanup!'
+ message='Finish environment cleanup!'
+ python3 /root/mugen/libs/locallibs/mugen_log.py --level info --message 'Finish environment cleanup!'
Thu Jul  6 20:32:53 2023 - INFO  - Finish environment cleanup!
